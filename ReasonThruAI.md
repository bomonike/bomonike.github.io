ReasonThruAI.md

When Generative AI burst on the scene in 2022, they were not able to count the number of "r"s in the word strawberry.

But in 2025, "reasoning" capabilities has been added to enable LLMs (Large Language Models) to <strong>explain</strong> how they solve multi-step word problems (using "Chain of Thought" processes).

Consequently, word problems from academic competitions and exams are being reused for assessing whether one AI version is better than another. (My notes on that at https://bomonike.github.io/ai-benchmarks).

This new advancement presents an opportunity for <strong>individual students</strong> to:
   * show off their skill at solving math, chemistry, biology and language translation problems
   * show potential employers that they can craft text prompts that extract value from AI tools
   * provide the world precise explanations of where AI can go wrong

Prospects for high-paying work now are greatest for those who are able to harness AI. 

Thus, I am creating a YouTube channel and related collaborative websites for students to 
<strong>accept and display videos that compare how Chain of Thought across different AI</strong>,
whether working or not.

This provides diligent students a <strong>competitive advantage</strong> at getting paid work managing AI.

That's because contributors provide <strong>actionable feedback to AI providers and users</strong>.

So I am also leveraging my contacts among AI companies for sponsorship of credits for our students.

Connect with me and message me if you are interested in making this happen for students.

// Wilson Mar
https://linkedin.com/in/wilsonmar


